{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8534a5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (14640, 15)\n",
      "\n",
      "Columns: Index(['tweet_id', 'airline_sentiment', 'airline_sentiment_confidence',\n",
      "       'negativereason', 'negativereason_confidence', 'airline',\n",
      "       'airline_sentiment_gold', 'name', 'negativereason_gold',\n",
      "       'retweet_count', 'text', 'tweet_coord', 'tweet_created',\n",
      "       'tweet_location', 'user_timezone'],\n",
      "      dtype='str')\n",
      "\n",
      "High Risk Distribution:\n",
      "high_risk\n",
      "1    9178\n",
      "0    5462\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"tweets.csv\")\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns)\n",
    "\n",
    "df = df[['text', 'airline_sentiment']]\n",
    "\n",
    "df = df.dropna(subset=['text'])\n",
    "\n",
    "# Create binary escalation risk label\n",
    "df['high_risk'] = df['airline_sentiment'].apply(\n",
    "    lambda x: 1 if x == 'negative' else 0\n",
    ")\n",
    "\n",
    "print(\"\\nHigh Risk Distribution:\")\n",
    "print(df['high_risk'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c366d916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rishi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5a0c994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0                @VirginAmerica What @dhepburn said.   \n",
      "1  @VirginAmerica plus you've added commercials t...   \n",
      "2  @VirginAmerica I didn't today... Must mean I n...   \n",
      "3  @VirginAmerica it's really aggressive to blast...   \n",
      "4  @VirginAmerica and it's a really big bad thing...   \n",
      "\n",
      "                                          clean_text  \n",
      "0                                               said  \n",
      "1      plus youve added commercials experience tacky  \n",
      "2       didnt today must mean need take another trip  \n",
      "3  really aggressive blast obnoxious entertainmen...  \n",
      "4                               really big bad thing  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    \n",
    "    # Remove mentions and hashtags\n",
    "    text = re.sub(r'@\\w+|#', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    return \" \".join(words)\n",
    "\n",
    "# Apply cleaning\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "print(df[['text', 'clean_text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7864baac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (11712, 5000)\n",
      "Testing shape: (2928, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['clean_text']\n",
    "y = df['high_risk']\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tfidf, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training shape:\", X_train.shape)\n",
    "print(\"Testing shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3483c106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.69      0.75      1092\n",
      "           1       0.83      0.91      0.87      1836\n",
      "\n",
      "    accuracy                           0.83      2928\n",
      "   macro avg       0.83      0.80      0.81      2928\n",
      "weighted avg       0.83      0.83      0.83      2928\n",
      "\n",
      "ROC-AUC Score: 0.9055145562498503\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18b762ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.001\n",
      "Precision: 0.627\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "\n",
    "# thresholds is 1 element shorter\n",
    "thresholds = np.append(thresholds, 1.0)\n",
    "\n",
    "for p, r, t in zip(precisions, recalls, thresholds):\n",
    "    if r >= 0.95:\n",
    "        print(\"Threshold:\", round(t, 3))\n",
    "        print(\"Precision:\", round(p, 3))\n",
    "        print(\"Recall:\", round(r, 3))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd5142d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Total_Cost</th>\n",
       "      <th>False_Negatives</th>\n",
       "      <th>False_Positives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>465500</td>\n",
       "      <td>10</td>\n",
       "      <td>831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>489000</td>\n",
       "      <td>1</td>\n",
       "      <td>968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>492000</td>\n",
       "      <td>30</td>\n",
       "      <td>684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>626500</td>\n",
       "      <td>76</td>\n",
       "      <td>493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>964000</td>\n",
       "      <td>159</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1528500</td>\n",
       "      <td>285</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>2484000</td>\n",
       "      <td>485</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>3971500</td>\n",
       "      <td>789</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>6409500</td>\n",
       "      <td>1281</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Threshold  Total_Cost  False_Negatives  False_Positives\n",
       "1        0.2      465500               10              831\n",
       "0        0.1      489000                1              968\n",
       "2        0.3      492000               30              684\n",
       "3        0.4      626500               76              493\n",
       "4        0.5      964000              159              338\n",
       "5        0.6     1528500              285              207\n",
       "6        0.7     2484000              485              118\n",
       "7        0.8     3971500              789               53\n",
       "8        0.9     6409500             1281                9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def calculate_cost(threshold):\n",
    "    y_pred_custom = (y_prob >= threshold).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_custom).ravel()\n",
    "    \n",
    "    cost = (fn * 5000) + (fp * 500)\n",
    "    return cost, fn, fp\n",
    "\n",
    "thresholds_to_test = np.linspace(0.1, 0.9, 9)\n",
    "\n",
    "results = []\n",
    "\n",
    "for t in thresholds_to_test:\n",
    "    cost, fn, fp = calculate_cost(t)\n",
    "    results.append((t, cost, fn, fp))\n",
    "\n",
    "cost_df = pd.DataFrame(results, columns=['Threshold', 'Total_Cost', 'False_Negatives', 'False_Positives'])\n",
    "\n",
    "cost_df.sort_values(\"Total_Cost\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
